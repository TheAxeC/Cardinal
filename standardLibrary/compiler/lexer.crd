
import "tokens" for Tokens

// The parser responsible for translating the source into tokens
class Parser {
	// current module we are working in
	field _module
	
	// path to the source
	field _sourcePath
	
	// the source
	field _source
	
	// current place in the source
	field _ind
	
	// current token
	field _currentToken
	
	// current line in the source
	field _currentLine
	
	// the previous token
	field _previousToken

	// indicates whether an error was found
	field _hasError

	lexError(error) {
		_hasError = true
		IO.print("  \x1b[1m\x1b[31merror:\x1b[0m ")args);
		IO.print("[", _sourcePath ," line ", _currentLine, "] Error: ")
		IO.println(error)
	}

	warning(warning) {
		var token = _previousToken

		if (token.type == Tokens::TokenType::TOKEN_ERROR) return

		IO.print("  \x1b[1m\x1b[33mwarning:\x1b[0m ")
		IO.print("[", _sourcePath ," line ", _currentLine, "] Warning: ")
		if (token.type == Tokens::TokenType::TOKEN_LINE) IO.print("newline: ")
		else if (token.type == Tokens::TokenType::TOKEN_EOF) IO.print("end of file: ")
		else IO.print(token)
		IO.println(warning)
	}

	error(error) {
		var token = _previousToken

		if (token.type == Tokens::TokenType::TOKEN_ERROR) return

		IO.print("  \x1b[1m\x1b[31merror:\x1b[0m ")
		IO.print("[", _sourcePath ," line ", _currentLine, "] Error: ")
		if (token.type == Tokens::TokenType::TOKEN_LINE) IO.print("newline: ")
		else if (token.type == Tokens::TokenType::TOKEN_EOF) IO.print("end of file: ")
		else IO.print(token.str)
		IO.println(error)
	}

}

